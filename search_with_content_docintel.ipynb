{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Azure imports\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, AnalyzeDocumentRequest\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Import content understanding client\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "# LangChain imports for text processing and embeddings\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "# Other imports\n",
    "import fitz\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Azure AI Services configs\n",
    "AZURE_AI_SERVICE_ENDPOINT = os.getenv(\"AZURE_AI_SERVICE_ENDPOINT\")\n",
    "AZURE_AI_SERVICE_API_VERSION = os.getenv(\"AZURE_AI_SERVICE_API_VERSION\") or \"2024-12-01-preview\"\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_VERSION\") or \"2024-11-30\"\n",
    "\n",
    "# Azure OpenAI configs\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_CHAT_API_VERSION = os.getenv(\"AZURE_OPENAI_CHAT_API_VERSION\") or \"2024-08-01-preview\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\") or \"2023-05-15\"\n",
    "\n",
    "# Azure Search configs\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_KEY = os.getenv(\"AZURE_SEARCH_KEY\")\n",
    "AZURE_SEARCH_INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") or \"multi-document-index\"\n",
    "\n",
    "# Document Intelligence configs\n",
    "DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "DOCUMENT_INTELLIGENCE_KEY = os.getenv(\"DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "# For content understanding\n",
    "ANALYZER_TEMPLATE_PATH = \"../analyzer_templates/image_chart_diagram_understanding.json\"\n",
    "ANALYZER_ID = \"content-understanding-search-sample-\" + str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up authentication\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "# Initialize clients\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=DOCUMENT_INTELLIGENCE_ENDPOINT,\n",
    "    api_version=\"2024-11-30\",\n",
    "    credential=AzureKeyCredential(DOCUMENT_INTELLIGENCE_KEY),\n",
    "    output=str('figures')\n",
    ")\n",
    "\n",
    "content_understanding_client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
    "    api_version=AZURE_AI_SERVICE_API_VERSION,\n",
    "    token_provider=token_provider,\n",
    "    subscription_key=os.getenv(\"AZURE_AI_SERVICE_KEY\"),\n",
    "    x_ms_useragent=\"azure-ai-content-understanding-python/multi-document-processor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created analyzer: content-understanding-search-sample-2e7835a6-2b7e-41a2-bc98-e41e32947184\n"
     ]
    }
   ],
   "source": [
    "# Create the analyzer for content understanding\n",
    "try:\n",
    "    response = content_understanding_client.begin_create_analyzer(ANALYZER_ID, analyzer_template_path=ANALYZER_TEMPLATE_PATH)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    print(f'Created analyzer: {result[\"result\"][\"analyzerId\"]}')\n",
    "except Exception as e:\n",
    "    print(f\"Error creating analyzer: {str(e)}\")\n",
    "    print(\"Using existing analyzer ID if available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def crop_image_from_pdf_page(pdf_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crops a region from a given page in a PDF and returns it as an image.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(page_number)\n",
    "    \n",
    "    # Cropping the page. The rect requires the coordinates in the format (x0, y0, x1, y1).\n",
    "    bbx = [x * 72 for x in bounding_box]\n",
    "    rect = fitz.Rect(bbx)\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72), clip=rect)\n",
    "    \n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    doc.close()\n",
    "    return img\n",
    "\n",
    "def format_content_understanding_result(content_understanding_result):\n",
    "    \"\"\"\n",
    "    Formats the JSON output of the Content Understanding result as Markdown for downstream usage in text.\n",
    "    \"\"\"\n",
    "    def _format_result(key, result):\n",
    "        result_type = result[\"type\"]\n",
    "        if result_type in [\"string\", \"integer\", \"number\", \"boolean\"]:\n",
    "            return f\"**{key}**: \" + str(result[f'value{result_type.capitalize()}']) + \"\\n\"\n",
    "        elif result_type == \"array\":\n",
    "            return f\"**{key}**: \" + ', '.join([str(result[\"valueArray\"][i][f\"value{r['type'].capitalize()}\"]) for i, r in enumerate(result[\"valueArray\"])]) + \"\\n\"\n",
    "        elif result_type == \"object\":\n",
    "            return f\"**{key}**\\n\" + ''.join([_format_result(f\"{key}.{k}\", result[\"valueObject\"][k]) for k in result[\"valueObject\"]])\n",
    "\n",
    "    fields = content_understanding_result['result']['contents'][0]['fields']\n",
    "    markdown_result = \"\"\n",
    "    for field in fields:\n",
    "        markdown_result += _format_result(field, fields[field])\n",
    "\n",
    "    return markdown_result\n",
    "\n",
    "def insert_figure_contents(md_content, figure_contents, span_offsets):\n",
    "    \"\"\"\n",
    "    Inserts the figure content for each of the provided figures in figure_contents\n",
    "    before the span offset of that figure in the given markdown content.\n",
    "    \"\"\"\n",
    "    # Validate span_offsets are sorted and strictly increasing\n",
    "    if span_offsets != sorted(span_offsets) or not all([o < span_offsets[i + 1] for i, o in enumerate(span_offsets) if i < len(span_offsets) - 1]):\n",
    "        raise ValueError(\"span_offsets should be sorted and strictly increasing.\")\n",
    "\n",
    "    # Split the content based on the provided spans\n",
    "    parts = []\n",
    "    preamble = None\n",
    "    for i, offset in enumerate(span_offsets):\n",
    "        if i == 0 and offset > 0:\n",
    "            preamble = md_content[0:offset]\n",
    "            parts.append(md_content[offset:span_offsets[i + 1]] if i + 1 < len(span_offsets) else md_content[offset:])\n",
    "        elif i == len(span_offsets) - 1:\n",
    "            parts.append(md_content[offset:])\n",
    "        else:\n",
    "            parts.append(md_content[offset:span_offsets[i + 1]])\n",
    "\n",
    "    # Join the parts back together with the figure content inserted\n",
    "    modified_content = \"\"\n",
    "    if preamble:\n",
    "        modified_content += preamble\n",
    "    for i, part in enumerate(parts):\n",
    "        modified_content += f\"<!-- FigureContent=\\\"{figure_contents[i]}\\\" -->\" + part\n",
    "\n",
    "    return modified_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(file_path):\n",
    "    \"\"\"Process a single document with Content Understanding and return its formatted content\"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"Processing {file_name}...\")\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        pdf_bytes = f.read()\n",
    "\n",
    "    # Use Document Intelligence to analyze the document\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-layout\",\n",
    "        AnalyzeDocumentRequest(bytes_source=pdf_bytes),\n",
    "        output=[str('figures')],\n",
    "        features=['ocrHighResolution'],\n",
    "        output_content_format=\"markdown\"\n",
    "    )\n",
    "\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    md_content = result.content\n",
    "    \n",
    "    # Process figures if available\n",
    "    figure_contents = []\n",
    "    if result.figures:\n",
    "        print(f\"Extracting {len(result.figures)} figure contents from {file_name}\")\n",
    "        for figure_idx, figure in enumerate(result.figures):\n",
    "            for region in figure.bounding_regions:\n",
    "                bounding_box = (\n",
    "                    region.polygon[0],  # x0 (left)\n",
    "                    region.polygon[1],  # y0 (top\n",
    "                    region.polygon[4],  # x1 (right)\n",
    "                    region.polygon[5]   # y1 (bottom)\n",
    "                )\n",
    "            \n",
    "            # Get page number for the figure\n",
    "            page_number = figure.bounding_regions[0]['pageNumber']\n",
    "            cropped_img = crop_image_from_pdf_page(file_path, page_number - 1, bounding_box)\n",
    "\n",
    "            # Create a folder structure with document name\n",
    "            doc_figures_dir = os.path.join(\"figures\", os.path.splitext(file_name)[0])\n",
    "            os.makedirs(doc_figures_dir, exist_ok=True)\n",
    "\n",
    "            figure_filename = f\"figure_{page_number}_{figure_idx + 1}.png\"\n",
    "            figure_filepath = os.path.join(doc_figures_dir, figure_filename)\n",
    "\n",
    "            # Save the figure\n",
    "            cropped_img.save(figure_filepath)\n",
    "            bytes_io = io.BytesIO()\n",
    "            cropped_img.save(bytes_io, format='PNG')\n",
    "            cropped_img = bytes_io.getvalue()\n",
    "\n",
    "            # Analyze the figure with Content Understanding\n",
    "            content_understanding_response = content_understanding_client.begin_analyze(ANALYZER_ID, figure_filepath)\n",
    "            content_understanding_result = content_understanding_client.poll_result(content_understanding_response, timeout_seconds=1000)\n",
    "            \n",
    "            # Get figure content and metadata\n",
    "            figure_content = format_content_understanding_result(content_understanding_result)\n",
    "            \n",
    "            # Add metadata to figure content\n",
    "            figure_metadata = {\n",
    "                \"document\": file_name,\n",
    "                \"page_number\": page_number,\n",
    "                \"figure_index\": figure_idx + 1,\n",
    "                \"content\": figure_content,\n",
    "                \"figure_path\": figure_filepath\n",
    "            }\n",
    "            \n",
    "            figure_contents.append(figure_metadata)\n",
    "            print(f\"Processed figure {figure_idx + 1} on page {page_number}\")\n",
    "\n",
    "        # Insert figure content into corresponding location in document\n",
    "        md_content = insert_figure_contents(\n",
    "            md_content, \n",
    "            [f[\"content\"] for f in figure_contents], \n",
    "            [f.spans[0][\"offset\"] for f in result.figures]\n",
    "        )\n",
    "    \n",
    "    # Save processed document to cache\n",
    "    cache_dir = \"cache\"\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    cache_file = os.path.join(cache_dir, f\"{os.path.splitext(file_name)[0]}.cache\")\n",
    "    \n",
    "    document_data = {\n",
    "        \"file_name\": file_name,\n",
    "        \"content\": md_content,\n",
    "        \"figures\": figure_contents,\n",
    "        \"raw_result\": result.as_dict(),\n",
    "        \"processed_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Save to cache file\n",
    "    with open(cache_file, 'w') as f:\n",
    "        json.dump(document_data, f)\n",
    "    \n",
    "    return document_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating analyzer: 409 Client Error: Conflict for url: https://gk-cu-aiservices.services.ai.azure.com/contentunderstanding/analyzers/content-understanding-search-sample-2e7835a6-2b7e-41a2-bc98-e41e32947184?api-version=2024-12-01-preview\n",
      "Using existing analyzer ID if available\n",
      "Found 50 PDF files to process\n",
      "Processing AC-SVU003A-EN_12012023.pdf...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 420\u001b[39m\n\u001b[32m    417\u001b[39m pdf_directory = \u001b[33m\"\u001b[39m\u001b[33m../data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;66;03m# Process and index documents\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m vector_store = \u001b[43mprocess_and_index_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAZURE_SEARCH_INDEX_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# Example search\u001b[39;00m\n\u001b[32m    423\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mExplain the defrost cycle in heat pumps\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 306\u001b[39m, in \u001b[36mprocess_and_index_documents\u001b[39m\u001b[34m(pdf_directory, index_name)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdf_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m PDF files to process\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# Process all documents\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m processed_documents = \u001b[43mprocess_multiple_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccessfully processed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(processed_documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Chunk each document and collect all chunks\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 179\u001b[39m, in \u001b[36mprocess_multiple_documents\u001b[39m\u001b[34m(file_paths)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         doc_data = \u001b[43mprocess_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m         processed_documents.append(doc_data)\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mprocess_document\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Use Document Intelligence to analyze the document\u001b[39;00m\n\u001b[32m     87\u001b[39m poller = document_intelligence_client.begin_analyze_document(\n\u001b[32m     88\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprebuilt-layout\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     89\u001b[39m     AnalyzeDocumentRequest(bytes_source=pdf_bytes),\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m     output_content_format=\u001b[33m\"\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     93\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m result: AnalyzeResult = \u001b[43mpoller\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m md_content = result.content\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# Process figures if available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vscodews/azure-ai-search-with-content-understanding-python-main/cenv/lib/python3.13/site-packages/azure/core/polling/_poller.py:254\u001b[39m, in \u001b[36mLROPoller.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> PollingReturnType_co:\n\u001b[32m    246\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[32m    248\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m \u001b[33;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._polling_method.resource()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vscodews/azure-ai-search-with-content-understanding-python-main/cenv/lib/python3.13/site-packages/azure/core/tracing/decorator.py:105\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m span_impl_type = settings.tracing_implementation()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vscodews/azure-ai-search-with-content-understanding-python-main/cenv/lib/python3.13/site-packages/azure/core/polling/_poller.py:269\u001b[39m, in \u001b[36mLROPoller.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:1092\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     timeout = \u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1092\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_multiple_documents(file_paths):\n",
    "    \"\"\"Process multiple documents and prepare them for indexing\"\"\"\n",
    "    processed_documents = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            doc_data = process_document(file_path)\n",
    "            processed_documents.append(doc_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "    \n",
    "    return processed_documents\n",
    "\n",
    "def chunk_document(document_data, chunk_size=512, chunk_overlap=20):\n",
    "    \"\"\"\n",
    "    Split a document into chunks for indexing, preserving metadata\n",
    "    \"\"\"\n",
    "    # Configure headers to split on\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\")\n",
    "    ]\n",
    "    \n",
    "    # First split text using Markdown headers\n",
    "    text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "    header_chunks = text_splitter.split_text(document_data[\"content\"])\n",
    "    \n",
    "    # Then further split the text using recursive character text splitting\n",
    "    char_text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"<!--\", \"\\n\\n\", \"#\"], \n",
    "        chunk_size=chunk_size, \n",
    "        chunk_overlap=chunk_overlap, \n",
    "        is_separator_regex=True\n",
    "    )\n",
    "    \n",
    "    # Convert to LangChain document format with metadata\n",
    "    chunks_with_metadata = []\n",
    "    \n",
    "    for i, chunk in enumerate(char_text_splitter.split_documents(header_chunks)):\n",
    "        # Start with base metadata\n",
    "        metadata = {\n",
    "            \"file_name\": document_data[\"file_name\"],\n",
    "            \"chunk_id\": i,\n",
    "            \"id\": f\"{document_data['file_name'].replace('.', '_')}_{i}\"\n",
    "        }\n",
    "        \n",
    "        # Extract page number if possible\n",
    "        page_number = None\n",
    "        \n",
    "        # Look for figure content in the chunk\n",
    "        figure_info = None\n",
    "        for fig in document_data[\"figures\"]:\n",
    "            if fig[\"content\"] in chunk.page_content:\n",
    "                figure_info = fig\n",
    "                page_number = fig[\"page_number\"]\n",
    "                break\n",
    "        \n",
    "        # Add figure metadata if found\n",
    "        if figure_info:\n",
    "            metadata.update({\n",
    "                \"figure_index\": figure_info[\"figure_index\"],\n",
    "                \"figure_path\": figure_info[\"figure_path\"],\n",
    "                \"section_type\": \"figure\"\n",
    "            })\n",
    "        else:\n",
    "            metadata[\"section_type\"] = \"text\"\n",
    "        \n",
    "        # Add page number (if found or inferred)\n",
    "        metadata[\"page_number\"] = page_number or 1\n",
    "        \n",
    "        # Add any header information from the chunk\n",
    "        if \"Header 1\" in chunk.metadata:\n",
    "            metadata[\"header_1\"] = chunk.metadata[\"Header 1\"]\n",
    "        if \"Header 2\" in chunk.metadata:\n",
    "            metadata[\"header_2\"] = chunk.metadata[\"Header 2\"]\n",
    "        if \"Header 3\" in chunk.metadata:\n",
    "            metadata[\"header_3\"] = chunk.metadata[\"Header 3\"]\n",
    "        \n",
    "        # Update the chunk metadata\n",
    "        chunk.metadata = metadata\n",
    "        chunks_with_metadata.append(chunk)\n",
    "    \n",
    "    return chunks_with_metadata\n",
    "\n",
    "def setup_vector_store(index_name, embedding_model_dimensions=1536):\n",
    "    \"\"\"\n",
    "    Set up Azure Search vector store with the required index structure\n",
    "    Returns the vector store instance ready for adding documents\n",
    "    \"\"\"\n",
    "    # Set up embeddings\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        openai_api_version=AZURE_OPENAI_EMBEDDING_API_VERSION,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    )\n",
    "    \n",
    "    # Set up vector store\n",
    "    vector_store = AzureSearch(\n",
    "        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        azure_search_key=AZURE_SEARCH_KEY,\n",
    "        index_name=index_name,\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "        fields={\n",
    "            \"file_name\": {\"type\": \"Edm.String\", \"filterable\": True, \"searchable\": True},\n",
    "            \"page_number\": {\"type\": \"Edm.Int32\", \"filterable\": True, \"sortable\": True},\n",
    "            \"section_type\": {\"type\": \"Edm.String\", \"filterable\": True, \"facetable\": True},\n",
    "            \"figure_index\": {\"type\": \"Edm.Int32\", \"filterable\": True},\n",
    "            \"figure_path\": {\"type\": \"Edm.String\", \"filterable\": False},\n",
    "            \"chunk_id\": {\"type\": \"Edm.Int32\", \"filterable\": True, \"sortable\": True},\n",
    "            \"header_1\": {\"type\": \"Edm.String\", \"filterable\": True, \"searchable\": True},\n",
    "            \"header_2\": {\"type\": \"Edm.String\", \"filterable\": True, \"searchable\": True},\n",
    "            \"header_3\": {\"type\": \"Edm.String\", \"filterable\": True, \"searchable\": True}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "def process_and_index_documents(pdf_directory, index_name):\n",
    "    \"\"\"\n",
    "    Main function to process multiple PDF files and index them\n",
    "    \"\"\"\n",
    "    # Find all PDF files in the directory\n",
    "    pdf_files = glob.glob(os.path.join(pdf_directory, \"*.pdf\"))\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in {pdf_directory}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    # Process all documents\n",
    "    processed_documents = process_multiple_documents(pdf_files)\n",
    "    print(f\"Successfully processed {len(processed_documents)} documents\")\n",
    "    \n",
    "    # Chunk each document and collect all chunks\n",
    "    all_chunks = []\n",
    "    for doc in processed_documents:\n",
    "        doc_chunks = chunk_document(doc)\n",
    "        all_chunks.extend(doc_chunks)\n",
    "        print(f\"Created {len(doc_chunks)} chunks from {doc['file_name']}\")\n",
    "    \n",
    "    # Set up vector store and add documents\n",
    "    vector_store = setup_vector_store(index_name)\n",
    "    vector_store.add_documents(documents=all_chunks)\n",
    "    \n",
    "    print(f\"Indexed {len(all_chunks)} chunks in total\")\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "def search_documents(vector_store, query, filter_criteria=None, top_k=5):\n",
    "    \"\"\"\n",
    "    Search for documents using vector search\n",
    "    \"\"\"\n",
    "    # Set up the retriever\n",
    "    search_params = {\"top\": top_k}\n",
    "    \n",
    "    if filter_criteria:\n",
    "        search_params[\"filter\"] = filter_criteria\n",
    "    \n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs=search_params\n",
    "    )\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    return retrieved_docs\n",
    "\n",
    "def generate_answer(query, retrieved_docs, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Generate an answer to the query using the retrieved documents as context\n",
    "    \"\"\"\n",
    "    # Helper function to generate the formatted context\n",
    "    def generate_context(chunks):\n",
    "        context = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            s = (f'Source {i} Metadata: {chunk.metadata}\\n'\n",
    "                 f'Source {i} Content: {chunk.page_content}')\n",
    "            context.append(s)\n",
    "        context = '\\n---\\n'.join(context)\n",
    "        return context\n",
    "    \n",
    "    # Remove redundant chunks\n",
    "    appeared = set()\n",
    "    unique_chunks = []\n",
    "    for chunk in retrieved_docs:\n",
    "        chunk_id = chunk.metadata['id']\n",
    "        if chunk_id not in appeared:\n",
    "            appeared.add(chunk_id)\n",
    "            unique_chunks.append(chunk)\n",
    "    \n",
    "    # Create context from unique chunks\n",
    "    context = generate_context(unique_chunks)\n",
    "    \n",
    "    # Define system prompt template\n",
    "    prompt = \"\"\"\n",
    "    You are an expert in document analysis. You are proficient in reading and analyzing technical reports. You are good at numerical reasoning and have a good understanding of financial concepts. You are given a question which you need to answer based on the references provided. To answer this question, you may first read the question carefully to know what information is required or helpful to answer the question. Then, you may read the references to find the relevant information.\n",
    "\n",
    "    If you find enough information to answer the question, you can first write down your thinking process and then provide a concise answer at the end.\n",
    "    If you find that there is not enough information to answer the question, you can state that there is insufficient information.\n",
    "    If you are not able or sure how to answer the question, say that you are not able to answer the question.\n",
    "    Do not provide any information that is not present in the references.\n",
    "    References are in markdown format, you may follow the markdown syntax to better understand the references.\n",
    "\n",
    "    ---\n",
    "    References:\n",
    "    {context}\n",
    "    ---\n",
    "\n",
    "    Now, here is the question:\n",
    "    ---\n",
    "    Question:\n",
    "    {question}\n",
    "    ---\n",
    "    Thinking Process::: \n",
    "    Answer::: \n",
    "    \"\"\"\n",
    "    \n",
    "    # Format the prompt\n",
    "    formatted_prompt = prompt.format(\n",
    "        question=query,\n",
    "        context=context\n",
    "    )\n",
    "    \n",
    "    # Set up the chat model\n",
    "    chat_llm = AzureChatOpenAI(\n",
    "        model=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        api_version=AZURE_OPENAI_CHAT_API_VERSION,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Generate the answer\n",
    "    answer = chat_llm.invoke(formatted_prompt)\n",
    "    \n",
    "    return answer.content\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory containing PDF files\n",
    "    pdf_directory = \"../data\"\n",
    "    \n",
    "    # Process and index documents\n",
    "    vector_store = process_and_index_documents(pdf_directory, AZURE_SEARCH_INDEX_NAME)\n",
    "    \n",
    "    # Example search\n",
    "    query = \"Explain the defrost cycle in heat pumps\"\n",
    "    \n",
    "    # Search with filters\n",
    "    # Example filter: \"file_name eq 'document1.pdf' and page_number gt 5\"\n",
    "    retrieved_docs = search_documents(vector_store, query, filter_criteria=None, top_k=5)\n",
    "    \n",
    "    # Generate answer\n",
    "    answer = generate_answer(query, retrieved_docs)\n",
    "    \n",
    "    # Print the answer\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
